{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e299e7b9",
   "metadata": {},
   "source": [
    "# Notebook 1 – Exploración de Datos (EDA) con Datos de Accidentes de Tránsito\n",
    "\n",
    "**Objetivo del notebook:**  \n",
    "Aprender a realizar una exploración de datos (EDA) básica y limpieza inicial usando un dataset real sobre accidentes de tránsito y seguros en distintos estados de EE. UU.\n",
    "\n",
    "**Dataset:**  \n",
    "Cada fila representa un estado y contiene indicadores de choques fatales y costos de seguros:\n",
    "\n",
    "- `Estado`\n",
    "- `Número de conductores involucrados en colisiones fatales por cada mil millones de millas`\n",
    "- `Porcentaje de conductores involucrados en colisiones fatales con exceso de velocidad`\n",
    "- `Porcentaje de conductores involucrados en colisiones fatales bajo la influencia del alcohol`\n",
    "- `Porcentaje de conductores involucrados en colisiones fatales que no estaban distraídos`\n",
    "- `Porcentaje de conductores involucrados en colisiones fatales que no habían estado involucrados en accidentes previos`\n",
    "- `Primas de seguro de automóvil ($)`\n",
    "- `Pérdidas incurridas por las compañías de seguros por colisiones por conductor asegurado ($)`\n",
    "\n",
    "En este notebook vamos a:\n",
    "\n",
    "1. Importar el dataset y entender su estructura.\n",
    "2. Revisar tipos de datos, valores faltantes y duplicados.\n",
    "3. Detectar outliers numéricos de forma simple.\n",
    "4. Crear algunas variables nuevas que tengan sentido analítico.\n",
    "5. Dejar un **dataframe limpio y listo** para usar en modelos en el siguiente notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Importar librerías y cargar el dataset\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Opciones de visualización\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('default')\n",
    "\n",
    "# Cargar el dataset (ajusta la ruta al archivo si es necesario)\n",
    "# Por ejemplo: 'bad-drivers.csv' en la misma carpeta del notebook\n",
    "df = pd.read_csv(\"bad-drivers.csv\")\n",
    "\n",
    "# Mirar las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b7323",
   "metadata": {},
   "source": [
    "## 2. Inspección inicial del dataset\n",
    "\n",
    "En esta sección queremos responder rápidamente:\n",
    "\n",
    "- ¿Cuántas filas y columnas tiene el dataset?\n",
    "- ¿Qué tipo de dato tiene cada columna?\n",
    "- ¿Hay valores faltantes?\n",
    "- ¿Cómo lucen las estadísticas básicas de las columnas numéricas?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del dataset\n",
    "print(\"Dimensiones del dataset (filas, columnas):\", df.shape)\n",
    "\n",
    "# Información general de tipos de datos y valores no nulos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de las columnas numéricas\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd440e09",
   "metadata": {},
   "source": [
    "### Preguntas rápidas (para discutir en voz alta / comentar en celdas Markdown):\n",
    "\n",
    "1. ¿Te llama la atención algún rango de valores (mínimo, máximo, promedio) en las variables numéricas?\n",
    "2. ¿Hay columnas con valores muy diferentes entre el mínimo y el máximo que podrían indicar presencia de **outliers**?\n",
    "3. ¿Qué columnas parecen claramente numéricas y cuál es la única claramente categórica?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01279be6",
   "metadata": {},
   "source": [
    "## 3. Renombrar columnas a un formato más manejable\n",
    "\n",
    "Los nombres originales son largos. Vamos a renombrarlos a `snake_case` para facilitar el trabajo en Python.\n",
    "\n",
    "Además, esto es una **buena práctica** para futuros modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar nombres de columnas originales\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de renombre de columnas\n",
    "\n",
    "rename_dict = {\n",
    "    \"Estado\": \"estado\",\n",
    "    \"Número de conductores involucrados en colisiones fatales por cada mil millones de millas\": \"conductores_fatales_mm_millas\",\n",
    "    \"Porcentaje de conductores involucrados en colisiones fatales con exceso de velocidad\": \"pct_exceso_velocidad\",\n",
    "    \"Porcentaje de conductores involucrados en colisiones fatales bajo la influencia del alcohol\": \"pct_alcohol\",\n",
    "    \"Porcentaje de conductores involucrados en colisiones fatales que no estaban distraídos\": \"pct_no_distraidos\",\n",
    "    \"Porcentaje de conductores involucrados en colisiones fatales que no habían estado involucrados en accidentes previos\": \"pct_sin_accidentes_previos\",\n",
    "    \"Primas de seguro de automóvil ($)\": \"primas_seguro\",\n",
    "    \"Pérdidas incurridas por las compañías de seguros por colisiones por conductor asegurado ($)\": \"perdidas_por_conductor\",\n",
    "}\n",
    "\n",
    "# Aplicar el cambio\n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "# Verificar\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209798c",
   "metadata": {},
   "source": [
    "## 4. Tipos de datos, valores faltantes y duplicados\n",
    "\n",
    "Antes de hacer modelos o gráficos, debemos asegurarnos de que:\n",
    "\n",
    "- Cada columna tenga el **tipo de dato correcto** (numérico vs categórico).\n",
    "- No haya **duplicados** problemáticos.\n",
    "- Conozcamos la magnitud de los **valores faltantes**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Revisar tipos de datos\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir `state` en tipo categórico (opcional pero recomendable)\n",
    "df[\"estado\"] = df[\"estado\"].astype(\"category\")\n",
    "\n",
    "# Verificamos de nuevo\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8094c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Valores faltantes (conteo y porcentaje)\n",
    "conteo_nulos = df.isna().sum()\n",
    "nulos_pct = (conteo_nulos / len(df) * 100).round(2)\n",
    "\n",
    "resumen_nulos = pd.DataFrame({\n",
    "    \"conteo_nulost\": conteo_nulos,\n",
    "    \"nulos_pct\": nulos_pct\n",
    "}).sort_values(by=\"nulos_pct\", ascending=False)\n",
    "\n",
    "resumen_nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Filas duplicadas\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(f\"Número de filas duplicadas en el dataset: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85ea7d",
   "metadata": {},
   "source": [
    "### EJERCICIO 1 (para que programen ustedes)\n",
    "\n",
    "1. Si existieran filas duplicadas, decidan si corresponde eliminarlas o no.  \n",
    "2. Si existieran valores faltantes, definan una estrategia simple (por ejemplo, eliminar filas con NA en variables críticas).\n",
    "\n",
    "> **Sugerencia**: usen `df.drop_duplicates()` y/o `df.dropna()` o imputación sencilla (media/mediana) si tiene sentido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 1: completa la limpieza según las decisiones de tu grupo.\n",
    "# A modo de ejemplo, aquí dejamos líneas comentadas:\n",
    "\n",
    "# 1) Eliminar filas completamente duplicadas\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 2) Si quisieran eliminar filas con NA en alguna columna específica:\n",
    "# cols_criticas = [\"drivers_fatal_per_billion_miles\", \"pct_speeding\", \"pct_alcohol\"]\n",
    "# df = df.dropna(subset=cols_criticas)\n",
    "\n",
    "# Muestra la nueva forma del dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955da22",
   "metadata": {},
   "source": [
    "## 5. Detección simple de outliers (z-score)\n",
    "\n",
    "Ahora vamos a detectar **outliers** numéricos usando un criterio sencillo:\n",
    "\n",
    "- Para cada columna numérica, calculamos el **z-score**.\n",
    "- Marcamos como outlier aquellos registros con |z| > 3 en al menos una columna.\n",
    "\n",
    "Esto no es perfecto, pero es un buen primer filtro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Seleccionar solo columnas numéricas\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff19a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular z-scores para cada columna numérica (ignorando filas con NA)\n",
    "z_scores = np.abs(stats.zscore(df[numeric_cols], nan_policy='omit'))\n",
    "\n",
    "# z_scores es un array; construimos una máscara de outliers\n",
    "outlier_mask = (z_scores > 3).any(axis=1)\n",
    "\n",
    "print(f\"Número de filas marcadas como outlier (|z|>3 en alguna variable numérica): {outlier_mask.sum()}\")\n",
    "\n",
    "# Mostrar algunas filas outlier para inspección\n",
    "df[outlier_mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de las columnas numéricas\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662eeae",
   "metadata": {},
   "source": [
    "## Outliers en la variable `pct_no_distraidos`\n",
    "\n",
    "Al analizar la distribución de esta variable, se identificaron dos valores que se alejan significativamente del rango típico:\n",
    "\n",
    "- **Mississippi** → `pct_no_distraidos = 10`\n",
    "- **Wisconsin** → `pct_no_distraidos = 39`\n",
    "\n",
    "Estos valores son **outliers** porque están muy por debajo del resto de los estados y pueden afectar análisis estadísticos y modelos predictivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b46ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 2: decide qué hacer con los outliers.\n",
    "\n",
    "# Ejemplo: eliminar outliers (si el grupo decide hacerlo)\n",
    "# df_clean = df[~outlier_mask].copy()\n",
    "\n",
    "# Ejemplo alternativo: mantenerlos, pero copiamos de todos modos\n",
    "df_clean = df.copy()\n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184eb8b",
   "metadata": {},
   "source": [
    "## 6. Creación de variables nuevas\n",
    "\n",
    "Vamos a crear algunas variables derivadas que pueden ser útiles luego para modelos:\n",
    "\n",
    "1. **ratio_losses_premiums**: qué proporción de las primas de seguro se “pierde” en siniestros.  \n",
    "   \\[\n",
    "   \\text{ratio\\_losses\\_premiums} = \\frac{\\text{losses\\_per\\_insured\\_driver}}{\\text{car\\_insurance\\_premiums}}\n",
    "   \\]\n",
    "\n",
    "2. **risk_speed_alcohol**: indicador simple de riesgo combinando % de choques con exceso de velocidad y % con alcohol.  \n",
    "   \\[\n",
    "   \\text{risk\\_speed\\_alcohol} = \\text{pct\\_speeding} + \\text{pct\\_alcohol}\n",
    "   \\]\n",
    "\n",
    "3. **pct_safe_behaviour**: porcentaje aproximado de conductores que en choques fatales *no estaban distraídos* y *no tenían accidentes previos*.  \n",
    "   (Esto es una aproximación solo para fines didácticos.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Crear ratio de pérdidas sobre primas\n",
    "df_clean[\"ratio_losses_premiums\"] = (\n",
    "    df_clean[\"perdidas_por_conductor\"] / df_clean[\"primas_seguro\"]\n",
    ")\n",
    "\n",
    "# 6.2 Crear indicador combinado de riesgo (velocidad + alcohol)\n",
    "df_clean[\"risk_speed_alcohol\"] = (\n",
    "    df_clean[\"pct_exceso_velocidad\"] + df_clean[\"pct_alcohol\"]\n",
    ")\n",
    "\n",
    "# 6.3 Aproximación de \"comportamiento seguro\" combinando no distraídos y sin accidentes previos\n",
    "# Ojo: esto no es una fórmula oficial, solo una aproximación pedagógica\n",
    "df_clean[\"pct_safe_behaviour\"] = (\n",
    "    df_clean[\"pct_no_distraidos\"] * df_clean[\"pct_sin_accidentes_previos\"] / 100.0\n",
    ")\n",
    "\n",
    "df_clean[[\n",
    "    \"estado\",\n",
    "    \"primas_seguro\",\n",
    "    \"perdidas_por_conductor\",\n",
    "    \"ratio_losses_premiums\",\n",
    "    \"risk_speed_alcohol\",\n",
    "    \"pct_safe_behaviour\"\n",
    "]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae293ac",
   "metadata": {},
   "source": [
    "## 7. Selección de variables (X) y variable objetivo (y)\n",
    "\n",
    "Para construir el modelo, definimos primero la **variable objetivo**, es decir, la columna que queremos predecir.  \n",
    "En este caso, el objetivo es:\n",
    "\n",
    "- **y:** `primas_seguro`\n",
    "\n",
    "Luego seleccionamos las **variables predictoras (X)**, que representan factores asociados al riesgo vial y a las pérdidas históricas de las aseguradoras.  \n",
    "Estas serán las entradas del modelo:\n",
    "\n",
    "- `conductores_fatales_mm_millas`\n",
    "- `pct_exceso_velocidad`\n",
    "- `pct_alcohol`\n",
    "- `pct_no_distraidos`\n",
    "- `pct_sin_accidentes_previos`\n",
    "- `perdidas_por_conductor`\n",
    "\n",
    "Con estas columnas se construye el DataFrame final para el modelado:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 3. Seleccionar X e y \n",
    "# ==========================\n",
    "\n",
    "# Variable objetivo (lo que queremos predecir)\n",
    "target_col = \"primas_seguro\"\n",
    "\n",
    "# Variables predictoras (características del modelo)\n",
    "feature_cols = [\n",
    "    \"conductores_fatales_mm_millas\",\n",
    "    \"pct_exceso_velocidad\",\n",
    "    \"pct_alcohol\",\n",
    "    \"pct_no_distraidos\",\n",
    "    \"pct_sin_accidentes_previos\",\n",
    "    \"perdidas_por_conductor\"\n",
    "]\n",
    "\n",
    "# Creamos un DataFrame con solo las columnas necesarias\n",
    "df_model = df_clean[feature_cols + [target_col]].copy()\n",
    "\n",
    "df_model.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d342f6",
   "metadata": {},
   "source": [
    "## 8. Checkpoint final del Notebook 1\n",
    "\n",
    "Al terminar este notebook deberías tener:\n",
    "\n",
    "- Un dataset con nombres de columnas limpios (`snake_case`).\n",
    "- Tipos de datos adecuados (estado como categoría, resto numérico).\n",
    "- Revisión (y decisión) sobre duplicados, valores faltantes y outliers.\n",
    "- Nuevas variables derivadas con sentido de negocio.\n",
    "- Un dataframe `model_df` listo para usar en el **Notebook 2 – Regresión Lineal**.\n",
    "\n",
    "### Preguntas de reflexión (para 5 minutos finales)\n",
    "\n",
    "1. ¿Qué variable crees que tendrá mayor impacto en las pérdidas de las aseguradoras (`losses_per_insured_driver`) y por qué?  \n",
    "2. ¿Qué decisiones de limpieza podrían cambiar fuertemente los resultados de un futuro modelo?  \n",
    "3. Si tuvieras que explicarle a alguien de negocio lo que hiciste en este notebook, ¿cómo lo resumirías en 3 frases?\n",
    "\n",
    "En la próxima sesión vamos a:\n",
    "\n",
    "- Dividir `model_df` en conjuntos de entrenamiento y prueba.\n",
    "- Entrenar un modelo de **regresión lineal**.\n",
    "- Evaluar métricas (MAE, RMSE, R²).\n",
    "- Analizar la importancia de las variables.\n",
    "\n",
    "Guarda este notebook: lo vas a reutilizar directamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d3103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
