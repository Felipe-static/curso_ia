{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7533f7f",
   "metadata": {},
   "source": [
    "# Notebook 2 — Regresión Lineal con datos de accidentes y seguros\n",
    "\n",
    "**Objetivo de la sesión**  \n",
    "Entrenar un primer modelo de **regresión lineal** para predecir **primas de seguro de auto** usando información de accidentes, y entender:\n",
    "\n",
    "- Cómo separar datos en **train / test**.  \n",
    "- Cómo entrenar `LinearRegression` de `scikit-learn`.  \n",
    "- Cómo evaluar el modelo con **MAE, RMSE, R²**.  \n",
    "- Cómo analizar **residuales** y **coeficientes** (variables más influyentes).\n",
    "\n",
    "Dataset (columnas utilizadas):\n",
    "\n",
    "- `State`  \n",
    "- `Number of drivers involved in fatal collisions per billion miles`  \n",
    "- `Percentage Of Drivers Involved In Fatal Collisions Who Were Speeding`  \n",
    "- `Percentage Of Drivers Involved In Fatal Collisions Who Were Alcohol-Impaired`  \n",
    "- `Percentage Of Drivers Involved In Fatal Collisions Who Were Not Distracted`  \n",
    "- `Percentage Of Drivers Involved In Fatal Collisions Who Had Not Been Involved In Any Previous Accidents`  \n",
    "- `Car Insurance Premiums ($)`  \n",
    "- `Losses incurred by insurance companies for collisions per insured driver ($)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23090f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 0. Importar librerías\n",
    "# ==========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a28fa",
   "metadata": {},
   "source": [
    "## 1. Cargar el dataset crudo\n",
    "\n",
    "En esta celda cargamos el archivo CSV original **sin modificaciones previas**.\n",
    "\n",
    "\n",
    "Ajusta la ruta al archivo según dónde lo tengas guardado (por ejemplo: `\"bad-drivers.csv\"` o `\"data/bad-drivers.csv\"`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 1. Cargar datos crudos\n",
    "# ==========================\n",
    "DATA_PATH = \"bad-drivers.csv\"\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Ver primeras filas para confirmar estructura\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b60c1",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Inspección general del dataset\n",
    "\n",
    "Antes de modelar, necesitamos entender:\n",
    "\n",
    "- Tipos de datos.  \n",
    "- Valores faltantes.  \n",
    "- Rangos de las variables numéricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del dataset crudo\n",
    "df_raw.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de las variables numéricas\n",
    "df_raw.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96241114",
   "metadata": {},
   "source": [
    "**Preguntas para comentar en grupo (rápido):**\n",
    "\n",
    "1. ¿Hay valores faltantes en alguna columna relevante?  \n",
    "2. ¿Alguna variable tiene un rango muy distinto a las demás (por ejemplo, más grande por varias órdenes de magnitud)?  \n",
    "3. ¿Cuál podría ser una buena **variable objetivo** (y) para un modelo de regresión?\n",
    "\n",
    "En este notebook asumiremos que queremos **predecir la prima de seguro**:\n",
    "\n",
    "> `y = Car Insurance Premiums ($)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1572288",
   "metadata": {},
   "source": [
    "## 3. Selección de variables para el modelo\n",
    "\n",
    "Vamos a construir un modelo sencillo que prediga:\n",
    "- `Car Insurance Premiums ($)` (variable objetivo)\n",
    "\n",
    "Usando como **features**:\n",
    "\n",
    "- `Number of drivers involved in fatal collisions per billion miles`\n",
    "- `Percentage Of Drivers Involved In Fatal Collisions Who Were Speeding`\n",
    "- `Percentage Of Drivers Involved In Fatal Collisions Who Were Alcohol-Impaired`\n",
    "- `Percentage Of Drivers Involved In Fatal Collisions Who Were Not Distracted`\n",
    "- `Percentage Of Drivers Involved In Fatal Collisions Who Had Not Been Involved In Any Previous Accidents`\n",
    "- `Losses incurred by insurance companies for collisions per insured driver ($)`\n",
    "\n",
    "La columna `State` la dejaremos fuera del primer modelo (es categórica y requeriría codificación adicional).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9836fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 3. Seleccionar X (features) e y (target)\n",
    "# ==========================\n",
    "\n",
    "target_col = \"Car Insurance Premiums ($)\"\n",
    "\n",
    "feature_cols = [\n",
    "    \"Number of drivers involved in fatal collisions per billion miles\",\n",
    "    \"Percentage Of Drivers Involved In Fatal Collisions Who Were Speeding\",\n",
    "    \"Percentage Of Drivers Involved In Fatal Collisions Who Were Alcohol-Impaired\",\n",
    "    \"Percentage Of Drivers Involved In Fatal Collisions Who Were Not Distracted\",\n",
    "    \"Percentage Of Drivers Involved In Fatal Collisions Who Had Not Been Involved In Any Previous Accidents\",\n",
    "    \"Losses incurred by insurance companies for collisions per insured driver ($)\"\n",
    "]\n",
    "\n",
    "# Nos quedamos solo con las columnas necesarias\n",
    "df_model = df_raw[feature_cols + [target_col]].copy()\n",
    "\n",
    "# Por simplicidad, eliminamos filas con NaN en estas columnas\n",
    "df_model = df_model.dropna()\n",
    "\n",
    "print(df_model.shape)\n",
    "df_model.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be86927c",
   "metadata": {},
   "source": [
    "## 4. Separar en entrenamiento y prueba (train / test split)\n",
    "\n",
    "Usaremos:\n",
    "\n",
    "- **X**: matriz de features.  \n",
    "- **y**: vector de primas de seguro.  \n",
    "- 80% de los datos para **entrenar** y 20% para **probar** el modelo.\n",
    "\n",
    "Usaremos `random_state` fijo para reproducibilidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70082017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 4. Train / Test Split\n",
    "# ==========================\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "y = df_model[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f3458",
   "metadata": {},
   "source": [
    "**Chequeo rápido:**\n",
    "\n",
    "- ¿Cuántos registros quedaron para entrenamiento y cuántos para prueba?  \n",
    "- ¿Ves algún desbalance evidente (muchos pocos datos)?\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Entrenar el modelo de Regresión Lineal\n",
    "\n",
    "Usaremos `LinearRegression()` de `scikit-learn`:\n",
    "\n",
    "- Ajusta un modelo lineal de la forma\n",
    "  $\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb20246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 5. Entrenar modelo LinearRegression\n",
    "# ==========================\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Intercepto (beta_0):\", linreg.intercept_)\n",
    "print(\"\\nCoeficientes:\")\n",
    "for col, coef in zip(feature_cols, linreg.coef_):\n",
    "    print(f\"{col}: {coef:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f79698",
   "metadata": {},
   "source": [
    "**Interpretación rápida de coeficientes:**\n",
    "\n",
    "- El intercepto es el valor de la prima de seguro cuando todas las variables explicativas valen 0 (aquí tiene menos interpretación directa, pero es parte del modelo).  \n",
    "- Cada coeficiente indica cómo cambia la **prima de seguro (en dólares)** cuando la variable correspondiente aumenta en 1 unidad, manteniendo las demás constantes.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Predicción y análisis de residuales\n",
    "\n",
    "Ahora vamos a:\n",
    "\n",
    "1. Obtener predicciones en el **conjunto de prueba**.  \n",
    "2. Calcular **residuales**:  \n",
    "   $ \\text{residual} = y_{\\text{real}} - y_{\\text{predicho}}$ \n",
    "   \n",
    "3. Graficar:\n",
    "   - `y_test` vs `y_pred` (dispersión).  \n",
    "   - Residuales vs `y_pred`.  \n",
    "   - Histograma de residuales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44034dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 6. Predicciones en el set de prueba\n",
    "# ==========================\n",
    "\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# Creamos un DataFrame auxiliar para análisis\n",
    "df_results = pd.DataFrame({\n",
    "    \"y_test\": y_test.values,\n",
    "    \"y_pred\": y_pred\n",
    "})\n",
    "df_results[\"residual\"] = df_results[\"y_test\"] - df_results[\"y_pred\"]\n",
    "\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f712d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispersión: valores reales vs predichos\n",
    "plt.figure()\n",
    "plt.scatter(df_results[\"y_test\"], df_results[\"y_pred\"])\n",
    "plt.xlabel(\"Prima real ($)\")\n",
    "plt.ylabel(\"Prima predicha ($)\")\n",
    "plt.title(\"Valores reales vs predichos\")\n",
    "plt.plot(\n",
    "    [df_results[\"y_test\"].min(), df_results[\"y_test\"].max()],\n",
    "    [df_results[\"y_test\"].min(), df_results[\"y_test\"].max()],\n",
    "    linestyle=\"--\"\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21120dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de residuales\n",
    "plt.figure()\n",
    "plt.hist(df_results[\"residual\"], bins=10)\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(\"Distribución de residuales\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559ae59",
   "metadata": {},
   "source": [
    "**Preguntas de análisis (para comentario rápido):**\n",
    "\n",
    "- ¿Los puntos en `y_real vs y_pred` se acercan a la diagonal?  \n",
    "- ¿Los residuales parecen estar centrados alrededor de 0?  \n",
    "- ¿Ves patrones claros (curvas, abanicos) en la gráfica de residuales vs predicción?  \n",
    "  - Si hay patrones fuertes, podría indicar que el modelo lineal es insuficiente.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Métricas de desempeño: MAE, RMSE, R²\n",
    "\n",
    "Vamos a calcular tres métricas clave:\n",
    "\n",
    "- **MAE** (Mean Absolute Error): error medio absoluto.  \n",
    "- **RMSE** (Root Mean Squared Error): error cuadrático medio en escala original.  \n",
    "- **R²**: proporción de varianza explicada por el modelo (entre 0 y 1, aunque puede ser negativa si el modelo es muy malo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91875edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 7. Cálculo de métricas\n",
    "# ==========================\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE : {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²  : {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3aa013",
   "metadata": {},
   "source": [
    "**Interpretación:**\n",
    "\n",
    "- **MAE** y **RMSE** están en **dólares**, por lo que se pueden comparar directamente con la magnitud típica de la prima.  \n",
    "- **R²** cerca de 1 indica que el modelo explica bien la variabilidad; cerca de 0 indica bajo poder explicativo.\n",
    "\n",
    "Discute con tu grupo:\n",
    "- Dado el rango de `Car Insurance Premiums ($)`, ¿estos errores son razonables?  \n",
    "- ¿El R² parece aceptable para un primer modelo simple?\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Variable más influyente (coeficientes)\n",
    "\n",
    "Vamos a ordenar los coeficientes del modelo según su valor absoluto para ver qué variables tienen mayor impacto en la prima de seguro (bajo el supuesto lineal del modelo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 8. Análisis de importancia de variables\n",
    "# ==========================\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"coef\": linreg.coef_\n",
    "})\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "\n",
    "coef_df_sorted = coef_df.sort_values(\"abs_coef\", ascending=False)\n",
    "coef_df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras de la magnitud de los coeficientes\n",
    "plt.figure()\n",
    "plt.barh(coef_df_sorted[\"feature\"], coef_df_sorted[\"coef\"])\n",
    "plt.xlabel(\"Coeficiente (impacto en la prima $)\")\n",
    "plt.title(\"Importancia de variables según regresión lineal\")\n",
    "plt.gca().invert_yaxis()  # la más importante arriba\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22f1c9",
   "metadata": {},
   "source": [
    "## 8.1 Mejora rápida: Eliminación de Outliers por Residuos\n",
    "\n",
    "Para asegurar una mejora en el modelo, vamos a identificar los puntos donde el modelo actual comete los errores más grandes (residuos altos) y los eliminaremos, ya que probablemente sean casos atípicos que ensucian la tendencia general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e66bd778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Original: -0.155\n",
      "R² Mejorado: 0.603\n",
      "MSE Original: 23641.706\n",
      "MSE Mejorado: 6254.461\n",
      "MAE Original: 119.546\n",
      "MAE Mejorado: 66.588\n",
      "\n",
      "Datos eliminados: 23\n"
     ]
    }
   ],
   "source": [
    "# Calculamos los residuos del modelo original (diferencia entre real y predicho)\n",
    "\n",
    "linreg_total = LinearRegression().fit(X, y)\n",
    "residuos = np.abs(y - linreg_total.predict(X))\n",
    "\n",
    "# Filtramos los datos que tengan un error menor a 1.5 desviaciones estándar\n",
    "# Esto elimina los datos más problemáticos que se desvían de la tendencia\n",
    "std_residuo = residuos.std()\n",
    "df_clean = df_model[residuos < 1.5 * std_residuo]\n",
    "\n",
    "# Entrenamos de nuevo con los datos limpios\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df_clean[feature_cols], df_clean[target_col], test_size=0.2, random_state=42)\n",
    "linreg2 = LinearRegression().fit(X_train2, y_train2)\n",
    "\n",
    "print(f\"R² Original: {r2:.3f}\")\n",
    "print(f\"R² Mejorado: {r2_score(y_test2, linreg2.predict(X_test2)):.3f}\")\n",
    "print(f\"MSE Original: {mean_squared_error(y_test, linreg_total.predict(X_test)):.3f}\")\n",
    "print(f\"MSE Mejorado: {mean_squared_error(y_test2, linreg2.predict(X_test2)):.3f}\")\n",
    "print(f\"MAE Original: {mean_absolute_error(y_test, linreg_total.predict(X_test)):.3f}\")\n",
    "print(f\"MAE Mejorado: {mean_absolute_error(y_test2, linreg2.predict(X_test2)):.3f}\\n\")\n",
    "print(f\"Datos eliminados: {len(df_model) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f79765d",
   "metadata": {},
   "source": [
    "**Mini-desafío:**\n",
    "\n",
    "En grupo, respondan:\n",
    "\n",
    "1. ¿Cuál es la **variable más influyente** según la magnitud del coeficiente?  \n",
    "2. ¿El signo del coeficiente (positivo/negativo) tiene sentido con la intuición del problema?  \n",
    "3. Usando tanto la tabla de coeficientes como las gráficas de residuales:  \n",
    "   - ¿Creen que este modelo lineal captura bien la relación entre variables?  \n",
    "   - ¿Qué mejoraría para una siguiente versión (más features, transformaciones, modelos no lineales, etc.)?\n",
    "4. ¿Consideran que vale la pena eliminar una gran cantidad de filas por un mejor modelo en un dominio acotado?\n",
    "---\n",
    "\n",
    "## 9. Cierre del Notebook 2\n",
    "\n",
    "En este notebook aprendimos a:\n",
    "\n",
    "- Partir desde el **dataset crudo**.  \n",
    "- Seleccionar una **variable objetivo** y un subconjunto de **features**.  \n",
    "- Dividir en **train/test**.  \n",
    "- Entrenar un modelo de **regresión lineal** con `scikit-learn`.  \n",
    "- Evaluar el desempeño con **MAE, RMSE, R²**.  \n",
    "- Analizar **residuales** y **coeficientes** para entender el comportamiento del modelo.\n",
    "\n",
    "En el siguiente paso, pueden:\n",
    "- Probar diferentes combinaciones de features.  \n",
    "- Agregar transformaciones (por ejemplo, escalar, log-transform).  \n",
    "- Comparar con otros modelos de regresión más avanzados.\n",
    "\n",
    "> Dejen guardado este notebook, porque será la base para conectarlo con otras sesiones del curso (por ejemplo, comparación con modelos más complejos o incorporación de nuevas variables).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
