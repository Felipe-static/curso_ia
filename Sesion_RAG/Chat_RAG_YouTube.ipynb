{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chat con Video de YouTube: Nuestro Primer Sistema RAG \n",
                "\n",
                "En este taller construiremos una **Inteligencia Artificial que puede \"ver\" un video de YouTube y responder preguntas sobre él**.\n",
                "\n",
                "Usaremos una técnica llamada **RAG (Retrieval-Augmented Generation)**.\n",
                "\n",
                "### Tecnologías que usaremos:\n",
                "- **Google Gemini**: El \"cerebro\" que genera las respuestas y crea los embeddings.\n",
                "- **ChromaDB**: Nuestra base de datos vectorial (memoria rápida).\n",
                "- **YouTube Transcript API**: Para leer los subtítulos del video."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Instalación de Librerías\n",
                "Primero, necesitamos instalar las herramientas necesarias en nuestro entorno."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6db22a23",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalamos las librerías necesarias\n",
                "%pip install -q -U google-generativeai chromadb youtube-transcript-api"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "77277bf9",
            "metadata": {},
            "source": [
                "## 2. Configuración Inicial\n",
                "Importamos las librerías y configuramos nuestra llave de acceso (API Key) para Google Gemini.\n",
                "\n",
                "Puedes obtener tu API Key en: https://aistudio.google.com/api-keys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "51e8afc0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import google.generativeai as genai\n",
                "import chromadb\n",
                "from youtube_transcript_api import YouTubeTranscriptApi\n",
                "import time\n",
                "\n",
                "# REEMPLAZA ESTO CON TU API KEY DE GOOGLE\n",
                "GOOGLE_API_KEY = \"TU API KEY\"\n",
                "\n",
                "genai.configure(api_key=GOOGLE_API_KEY)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e581abbe",
            "metadata": {},
            "source": [
                "## 3. Ingesta de Datos (Creando la Base de Conocimiento)\n",
                "Para que la IA sepa sobre el video, primero necesitamos extraer el texto (transcripción)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b03ec59",
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_transcript(youtube_url):\n",
                "    \"\"\"Obtiene la lista de objetos de transcripción (texto + tiempo) en lugar de solo texto plano\"\"\"\n",
                "    try:\n",
                "        if \"v=\" in youtube_url:\n",
                "            video_id = youtube_url.split(\"v=\")[1].split(\"&\")[0]\n",
                "        else:\n",
                "            video_id = youtube_url\n",
                "\n",
                "        ytt_api = YouTubeTranscriptApi()\n",
                "        transcript_list_obj = ytt_api.list(video_id)\n",
                "        transcript = transcript_list_obj.find_transcript(['es', 'en'])\n",
                "        return transcript.fetch() # Devolvemos la lista completa con tiempos\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        return None\n",
                "\n",
                "VIDEO_URL = \"https://www.youtube.com/watch?v=N_pbqiocSAE\"\n",
                "video_data = extract_transcript(VIDEO_URL)\n",
                "\n",
                "if video_data:\n",
                "    print(\"Transcripción extraída con éxito!\")\n",
                "    print(f\"Total de frases: {len(video_data)}\")\n",
                "    print(f\"Ejemplo: {video_data[0].text} (Inicio: {video_data[0].start}s)\")\n",
                "else:\n",
                "    print(\"No se pudo extraer la transcripción.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5dd2bd7d",
            "metadata": {},
            "source": [
                "## 4. Chunking (Dividir para Conquistar)\n",
                "Los modelos de IA tienen un límite de cuánto texto pueden leer a la vez. Además, para buscar información específica, **es mejor tener fragmentos pequeños y enfocados**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0236b1f0",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_smart_chunks(raw_transcript, chunk_size=1000):\n",
                "    \"\"\"Agrupa texto preservando el Timestamp de inicio\"\"\"\n",
                "    chunks = []\n",
                "    current_chunk_text = \"\"\n",
                "    current_start_time = 0.0\n",
                "    \n",
                "    if raw_transcript:\n",
                "        current_start_time = raw_transcript[0].start\n",
                "\n",
                "    for item in raw_transcript:\n",
                "        text = item.text\n",
                "        # Si iniciamos grupo nuevo, guardamos tiempo\n",
                "        if current_chunk_text == \"\":\n",
                "            current_start_time = item.start\n",
                "            \n",
                "        current_chunk_text += \" \" + text\n",
                "        \n",
                "        if len(current_chunk_text) >= chunk_size:\n",
                "            # Formato MM:SS\n",
                "            minutes = int(current_start_time // 60)\n",
                "            seconds = int(current_start_time % 60)\n",
                "            time_str = f\"{minutes:02d}:{seconds:02d}\"\n",
                "            \n",
                "            chunks.append({\"text\": current_chunk_text.strip(), \"timestamp\": time_str})\n",
                "            current_chunk_text = \"\"\n",
                "            \n",
                "    # Último chunk\n",
                "    if current_chunk_text:\n",
                "        minutes = int(current_start_time // 60)\n",
                "        seconds = int(current_start_time % 60)\n",
                "        chunks.append({\"text\": current_chunk_text.strip(), \"timestamp\": f\"{minutes:02d}:{seconds:02d}\"})\n",
                "        \n",
                "    return chunks\n",
                "\n",
                "# Dividimos el texto inteligentemente\n",
                "chunks = create_smart_chunks(video_data)\n",
                "\n",
                "print(f\"Texto dividido en {len(chunks)} fragmentos con metadata.\")\n",
                "print(f\"Ejemplo Chunk 1 [{chunks[0]['timestamp']}]: {chunks[0]['text'][:100]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "121fce98",
            "metadata": {},
            "source": [
                "## 5. Embeddings y Base de Datos Vectorial (ChromaDB)\n",
                "Aquí ocurre la magia. Convertiremos cada \"chunk\" de texto en una lista de números llamada **Embedding**. Los embeddings representan el **significado** del texto.\n",
                "\n",
                "Guardaremos estos embeddings en **ChromaDB** para poder buscar rápidamente después."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9aa9f519",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Inicializamos ChromaDB\n",
                "chroma_client = chromadb.Client()\n",
                "collection_name = \"youtube_rag_data\"\n",
                "try:\n",
                "    chroma_client.delete_collection(name=collection_name)\n",
                "except:\n",
                "    pass\n",
                "collection = chroma_client.create_collection(name=collection_name)\n",
                "\n",
                "print(\"Generando embeddings y guardando...\")\n",
                "\n",
                "documents = []\n",
                "metadatas = []\n",
                "ids = []\n",
                "embeddings = []\n",
                "\n",
                "for i, chunk in enumerate(chunks):\n",
                "    # Generamos el embedding\n",
                "    response = genai.embed_content(\n",
                "        model=\"models/text-embedding-004\",\n",
                "        content=chunk['text'],\n",
                "        task_type=\"retrieval_document\"\n",
                "    )\n",
                "    \n",
                "    # Guardamos Texto Y Metadata (Tiempo)\n",
                "    documents.append(chunk['text'])\n",
                "    metadatas.append({\"timestamp\": chunk['timestamp']})\n",
                "    ids.append(str(i))\n",
                "    embeddings.append(response['embedding'])\n",
                "\n",
                "collection.add(\n",
                "    documents=documents,\n",
                "    embeddings=embeddings,\n",
                "    metadatas=metadatas,\n",
                "    ids=ids\n",
                ")\n",
                "\n",
                "print(\"¡Base de conocimiento lista!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c6ea58e4",
            "metadata": {},
            "source": [
                "## 6. El Cerebro\n",
                "Ahora uniremos todo.\n",
                "\n",
                "Cuando hagas una pregunta:\n",
                "1. **Búsqueda**: Se convierte tu pregunta en números y buscaremos los chunks más parecidos en ChromaDB.\n",
                "2. **Contexto**: Tomaremos esos chunks y se los mostraremos a la IA.\n",
                "3. **Respuesta**: La IA responderá usando *sólo* esa información."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0206cab5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuramos modelo (Usamos Flash por estabilidad)\n",
                "model = genai.GenerativeModel('models/gemini-2.5-flash')\n",
                "chat_history = []\n",
                "\n",
                "def generate_answer(system_prompt):\n",
                "    \"\"\"INTENTO DE GENERACIÓN CON RETRY\"\"\"\n",
                "    try:\n",
                "        return model.generate_content(system_prompt).text\n",
                "    except Exception as e:\n",
                "        if \"429\" in str(e) or \"ResourceExhausted\" in str(e):\n",
                "            print(\"Cuota agotada. Esperando 60s...\")\n",
                "            time.sleep(60)\n",
                "            return generate_answer(system_prompt)\n",
                "        raise e\n",
                "\n",
                "def ask_video(question):\n",
                "    print(f\"\\n Tú: {question}\")\n",
                "    \n",
                "    # PASO 1: RETRIEVAL\n",
                "    try:\n",
                "        q_emb = genai.embed_content(\n",
                "            model=\"models/text-embedding-004\",\n",
                "            content=question,\n",
                "            task_type=\"retrieval_query\"\n",
                "        )['embedding']\n",
                "        \n",
                "        results = collection.query(\n",
                "            query_embeddings=[q_emb],\n",
                "            n_results=3\n",
                "        )\n",
                "        \n",
                "        # Preparar Contexto con Tiempos\n",
                "        context_parts = []\n",
                "        print(\"\\n [Fuentes]:\")\n",
                "        for i, doc in enumerate(results['documents'][0]):\n",
                "            ts = results['metadatas'][0][i]['timestamp']\n",
                "            print(f\"-- [{ts}] {doc[:80]}...\")\n",
                "            context_parts.append(f\"({ts}) {doc}\")\n",
                "\n",
                "        # PASO 2: PROMPT CON HISTORIA\n",
                "        # FIX: Calculamos la string fuera del f-string para evitar SyntaxError por backslash\n",
                "        history_text = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in chat_history[-3:]])\n",
                "        context_joined = \"\\n\".join(context_parts)\n",
                "        \n",
                "        prompt = f\"\"\"\n",
                "        Eres un asistente experto. Responde basándote en el contexto.\n",
                "        HISTORIAL:\n",
                "        {history_text}\n",
                "        CONTEXTO:\n",
                "        {context_joined}\n",
                "        PREGUNTA: {question}\n",
                "        INSTRUCCIÓN: \n",
                "        1. Tienes MEMORIA: usa el historial para entender preguntas como \"¿Y qué más?\" o referencias a lo anterior.\n",
                "        2. DEBES CITAR: Al final de cada afirmación importante, pon el timestamp entre corchetes. Ejemplo: \"Según el video, las neuronas se activan [05:32].\"\n",
                "        3. Si no sabes la respuesta, dilo.\n",
                "        \"\"\"\n",
                "        \n",
                "        # PASO 3: GENERACIÓN\n",
                "        answer = generate_answer(prompt)\n",
                "        print(f\"\\n IA: {answer}\")\n",
                "        \n",
                "        chat_history.append({\"role\": \"Usuario\", \"content\": question})\n",
                "        chat_history.append({\"role\": \"IA\", \"content\": answer})\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "\n",
                "# BUCLE\n",
                "print(\"\\n\" + \"=\"*40)\n",
                "print(\"¡Chat listo! Escribe 'exit' para salir.\")\n",
                "print(\"=\"*40 + \"\\n\")\n",
                "\n",
                "while True:\n",
                "    user_input = input(\"Tú: \")\n",
                "    if user_input.lower() in ['exit', 'salir', 'quit']:\n",
                "        print(\"¡Hasta luego!\")\n",
                "        break\n",
                "    ask_video(user_input)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
